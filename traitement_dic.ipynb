{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 0: We open the file entitled “distances3.txt” "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "\n",
    "# Read the .txt file\n",
    "with open('distances3.txt', 'r') as file:\n",
    "    lines = file.readlines()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: We separate our text into 20 lists "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_1 = []\n",
    "liste_2 = []\n",
    "liste_3 = []\n",
    "liste_4 = []\n",
    "liste_5 = []\n",
    "liste_6 = []\n",
    "liste_7 = []\n",
    "liste_8 = []\n",
    "liste_9 = []\n",
    "liste_10 = []\n",
    "liste_11 = []\n",
    "liste_12 = []\n",
    "liste_13 = []\n",
    "liste_14 = []\n",
    "liste_15 = []\n",
    "liste_16 = []\n",
    "liste_17 = []\n",
    "liste_18 = []\n",
    "liste_19 = []\n",
    "liste_20 = []\n",
    "\n",
    "\n",
    "for (i,line) in enumerate(lines) :\n",
    " # Suppress spaces and line break\n",
    "    line = line.strip()\n",
    "    \n",
    "# Check if the line is empty (if necessary)\n",
    "    if not line:\n",
    "        continue\n",
    "\n",
    "    # Separate the line in key and value (the last part is the value)\n",
    "    key_value = line.rsplit(maxsplit=1)  # Use rsplit to separate only at the last space occurrence\n",
    "    if i%21==0:\n",
    "        liste_1.append(key_value[1])\n",
    "    elif i%21==1:\n",
    "        liste_2.append(key_value[1])\n",
    "    elif i%21==2:\n",
    "        liste_3.append(key_value[1])\n",
    "    elif i%21==3:\n",
    "        liste_4.append(key_value[1])\n",
    "    elif i%21==4:\n",
    "        liste_5.append(key_value[1])\n",
    "    elif i%21==5:\n",
    "        liste_6.append(key_value[1])\n",
    "    elif i%21==6:\n",
    "        liste_7.append(key_value[1])\n",
    "    elif i%21==7:\n",
    "        liste_8.append(key_value[1])\n",
    "    elif i%21==8:\n",
    "        liste_9.append(key_value[1])\n",
    "    elif i%21==9:\n",
    "        liste_10.append(key_value[1])\n",
    "    elif i%21==10:\n",
    "        liste_11.append(key_value[1])\n",
    "    elif i%21==11:\n",
    "        liste_12.append(key_value[1])\n",
    "    elif i%21==12:\n",
    "        liste_13.append(key_value[1])\n",
    "    elif i%21==13:\n",
    "        liste_14.append(key_value[1])\n",
    "    elif i%21==14:\n",
    "        liste_15.append(key_value[1])\n",
    "    elif i%21==15:\n",
    "        liste_16.append(key_value[1])\n",
    "    elif i%21==16:\n",
    "        liste_17.append(key_value[1])\n",
    "    elif i%21==17:\n",
    "        liste_18.append(key_value[1])\n",
    "    elif i%21==18:\n",
    "        liste_19.append(key_value[1])\n",
    "    elif i%21==19:\n",
    "        liste_20.append(key_value[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: We join the 20 lists into a unique list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_finale = [liste_1,liste_2,liste_3,liste_4,liste_5,liste_6,liste_7,liste_8,liste_9,liste_10,liste_11,liste_12,liste_13,liste_14,liste_15,liste_16,liste_17,liste_18,liste_19,liste_20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: We transform this list into a data frame "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      identifiantpp code_civilité                 Nom     Prénom RPPS_doc  \\\n",
      "0       10000010107           MME  EMMANUEL-POINCELOT  Georgette      NaN   \n",
      "1       10000010867             M             TACONET  CHRISTIAN      NaN   \n",
      "2       10000011808           MME               HAMOT       ENNA      NaN   \n",
      "3       10000012129             M              DIDDEN  JEAN-PAUL      NaN   \n",
      "4       10000012558             M            CHUBERRE       YVES      NaN   \n",
      "...             ...           ...                 ...        ...      ...   \n",
      "97359   10110318689           MME               NABTI     Dahlia      NaN   \n",
      "97360   10110318705           MME         LAOUISSETTE     Meriem      NaN   \n",
      "97361   10110318713             M      RAZAFIMANDIMBY  Jean-Marc      NaN   \n",
      "97362   10110318739           MME             DAHMANI    Kamélia      NaN   \n",
      "97363   10110318770           MME                SAHI    Keltoum      NaN   \n",
      "\n",
      "      code_geo     xcl      ycl Nb_doct_2km Nb_doct_8km Nb_doct_30km  \\\n",
      "0        33485  453877  6419206    0.001576    0.012605     0.280462   \n",
      "1        95637  628442  6881566    0.000811     0.02166     0.079089   \n",
      "2        75056  652492  6862009    0.508671    0.508671     0.508671   \n",
      "3        11304  633310  6197645     0.00191    0.002865     0.037249   \n",
      "4        56034  243618  6738059    0.002364    0.006618     0.196644   \n",
      "...        ...     ...      ...         ...         ...          ...   \n",
      "97359    94044  661798  6850019    0.001697    0.042489     0.074973   \n",
      "97360    93047  668525  6867016    0.002285    0.024031     0.071842   \n",
      "97361    94043  652771  6857107    0.006609    0.033452     0.086526   \n",
      "97362    40192  418758  6316438    0.005842    0.005909     0.010917   \n",
      "97363    94078  659380  6847987     0.00198    0.023762      0.06087   \n",
      "\n",
      "      Nb_doct_f_2km Nb_doct_f_8km Nb_doct_f_30km Nb_doct_D_2km Nb_doct_D_8km  \\\n",
      "0           0.00105      0.009979       0.113445           0.0       0.00105   \n",
      "1          0.000562      0.010986       0.039388      0.000125      0.001248   \n",
      "2          0.271865      0.271865       0.271865      0.027698      0.027698   \n",
      "3          0.000318      0.000637       0.015918           0.0           0.0   \n",
      "4          0.001654      0.004491       0.107303           0.0      0.000236   \n",
      "...             ...           ...            ...           ...           ...   \n",
      "97359      0.000954      0.024001       0.041676      0.000177      0.002545   \n",
      "97360      0.001178      0.011569       0.035885       0.00025      0.002107   \n",
      "97361      0.003794      0.017827       0.048097      0.000449      0.002611   \n",
      "97362      0.003005      0.003038       0.005308      0.000267      0.000267   \n",
      "97363      0.000947      0.012828       0.033836      0.000115      0.001578   \n",
      "\n",
      "      Nb_doct_D_30km Nb_doct_f_D_2km Nb_doct_f_D_8km Nb_doct_f_D_30km  \n",
      "0           0.017857             0.0        0.012605         0.280462  \n",
      "1           0.006866        0.000062         0.02166         0.079089  \n",
      "2           0.027698        0.017218        0.508671         0.508671  \n",
      "3           0.001273             0.0        0.002865         0.037249  \n",
      "4           0.008509             0.0        0.006618         0.196644  \n",
      "...              ...             ...             ...              ...  \n",
      "97359       0.005055        0.000141        0.042489         0.074973  \n",
      "97360       0.005892        0.000143        0.024031         0.071842  \n",
      "97361       0.005834        0.000286        0.033452         0.086526  \n",
      "97362       0.000601        0.000067        0.005909         0.010917  \n",
      "97363       0.004104        0.000029        0.023762          0.06087  \n",
      "\n",
      "[97364 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "dataF = pd.DataFrame(list(zip(*liste_finale)))\n",
    "dataF.rename(columns={0: 'identifiantpp',1: 'code_civilité',2: 'Nom',3: 'Prénom',4: 'RPPS_doc',5: 'code_geo',6: 'xcl',7: 'ycl',8: 'Nb_doct_2km',9: 'Nb_doct_8km',10: 'Nb_doct_30km',11: 'Nb_doct_f_2km',12: 'Nb_doct_f_8km',13: 'Nb_doct_f_30km',14: 'Nb_doct_D_2km',15: 'Nb_doct_D_8km',16: 'Nb_doct_D_30km',17: 'Nb_doct_f_D_2km',18: 'Nb_doct_f_D_8km',19: 'Nb_doct_f_D_30km'}, inplace=True)\n",
    "print(dataF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 4: We add the good code commune to medecin_gen to do a good merge with dataF later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5267, 106)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medecin_gen = pd.read_csv('medecin_gen.csv')\n",
    "medecin_gen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'level_0', 'identifiantpp', 'identificationnationalepp',\n",
       "       'codecivilité', 'nomdexercice', 'prénomdexercice',\n",
       "       'codecatégorieprofessionnelle', 'codesavoirfaire', 'libellésavoirfaire',\n",
       "       ...\n",
       "       'Population', 'Superficie', 'Naissances', 'Deces', 'Logements',\n",
       "       'Ménages', 'MED14', 'Population_P_actif', 'Chomeurs', 'Actifs'],\n",
       "      dtype='object', length=106)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "medecin_gen.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "medecin_gen['RPPS'] = medecin_gen['RPPS'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\miniconda\\Lib\\site-packages\\pyogrio\\geopandas.py:261: UserWarning: More than one layer found in 'a-com2022-topo-2154.json': 'a_com2022' (default), 'a_reg2022', 'a_dep2022'. Specify layer parameter to avoid this warning.\n",
      "  result = read_func(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>codgeo</th>\n",
       "      <th>dep</th>\n",
       "      <th>reg</th>\n",
       "      <th>xcl2154</th>\n",
       "      <th>ycl2154</th>\n",
       "      <th>libgeo</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>01001</td>\n",
       "      <td>01</td>\n",
       "      <td>84</td>\n",
       "      <td>848241</td>\n",
       "      <td>6563021</td>\n",
       "      <td>L'Abergement-Clémenciat</td>\n",
       "      <td>POLYGON ((846981.436 6564107.36, 847017.457 65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>None</td>\n",
       "      <td>01002</td>\n",
       "      <td>01</td>\n",
       "      <td>84</td>\n",
       "      <td>887495</td>\n",
       "      <td>6548152</td>\n",
       "      <td>L'Abergement-de-Varey</td>\n",
       "      <td>POLYGON ((886027.651 6548170.9, 886157.325 654...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>None</td>\n",
       "      <td>01004</td>\n",
       "      <td>01</td>\n",
       "      <td>84</td>\n",
       "      <td>882724</td>\n",
       "      <td>6542583</td>\n",
       "      <td>Ambérieu-en-Bugey</td>\n",
       "      <td>POLYGON ((884889.404 6539629.931, 884795.75 65...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>None</td>\n",
       "      <td>01005</td>\n",
       "      <td>01</td>\n",
       "      <td>84</td>\n",
       "      <td>847277</td>\n",
       "      <td>6545791</td>\n",
       "      <td>Ambérieux-en-Dombes</td>\n",
       "      <td>POLYGON ((845951.25 6547999.078, 846073.72 654...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>01006</td>\n",
       "      <td>01</td>\n",
       "      <td>84</td>\n",
       "      <td>902191</td>\n",
       "      <td>6519791</td>\n",
       "      <td>Ambléon</td>\n",
       "      <td>POLYGON ((901336.361 6521123.305, 902460.201 6...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     id codgeo dep reg  xcl2154  ycl2154                   libgeo  \\\n",
       "0  None  01001  01  84   848241  6563021  L'Abergement-Clémenciat   \n",
       "1  None  01002  01  84   887495  6548152    L'Abergement-de-Varey   \n",
       "2  None  01004  01  84   882724  6542583        Ambérieu-en-Bugey   \n",
       "3  None  01005  01  84   847277  6545791      Ambérieux-en-Dombes   \n",
       "4  None  01006  01  84   902191  6519791                  Ambléon   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((846981.436 6564107.36, 847017.457 65...  \n",
       "1  POLYGON ((886027.651 6548170.9, 886157.325 654...  \n",
       "2  POLYGON ((884889.404 6539629.931, 884795.75 65...  \n",
       "3  POLYGON ((845951.25 6547999.078, 846073.72 654...  \n",
       "4  POLYGON ((901336.361 6521123.305, 902460.201 6...  "
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gdf = gpd.read_file('data/a-com2022-topo-2154.json')\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def codecom2(codecom1):\n",
    "    if str(codecom1).startswith('75'):\n",
    "        return('75056')\n",
    "    elif str(codecom1).startswith('693'):\n",
    "        return('69123')\n",
    "    elif str(codecom1).startswith('132'):\n",
    "        return('13055')\n",
    "    elif str(codecom1).startswith('91182'):\n",
    "        return('91228')\n",
    "    elif str(codecom1).startswith('85257'):\n",
    "        return('85090')\n",
    "    elif str(codecom1).startswith('85217'):\n",
    "        return('85146')\n",
    "    elif str(codecom1).startswith('85166'):\n",
    "        return('85194')\n",
    "    elif str(codecom1).startswith('74011'):\n",
    "        return('74010')\n",
    "    elif str(codecom1).startswith('74181'):\n",
    "        return('74112')\n",
    "    elif str(codecom1).startswith('74268') or str(codecom1).startswith('74093') or str(codecom1).startswith('74217'):\n",
    "        return('74010')\n",
    "    elif str(codecom1).startswith('50203'):\n",
    "        return('50129')\n",
    "    elif str(codecom1).startswith('59540'):\n",
    "        return('59139')\n",
    "    elif str(codecom1).startswith('49199'):\n",
    "        return('71291')\n",
    "    elif str(codecom1).startswith('29052'):\n",
    "        return('29003')\n",
    "    elif str(codecom1).startswith('85060'):\n",
    "        return('85194')\n",
    "    elif str(codecom1).startswith('50602'):\n",
    "        return('50129')\n",
    "    elif str(codecom1).startswith('49285'):\n",
    "        return('49301')\n",
    "    elif str(codecom1).startswith('85107'):\n",
    "        return('85146')\n",
    "    elif str(codecom1).startswith('50173'):\n",
    "        return('50129')\n",
    "    elif str(codecom1).startswith('49065'):\n",
    "        return('49080')   \n",
    "    elif str(codecom1).startswith('49375'):\n",
    "        return('49023')\n",
    "    elif str(codecom1).startswith('85069'):\n",
    "        return('85008')  \n",
    "    elif str(codecom1).startswith('85069'):\n",
    "        return('85008')   \n",
    "    elif str(codecom1).startswith('49276'):\n",
    "        return('49244') \n",
    "    elif str(codecom1).startswith('49273'):\n",
    "        return('49301')\n",
    "    elif 'A' in str(codecom1):\n",
    "        return(str(codecom1).replace('A','0'))\n",
    "    elif 'B' in str(codecom1):\n",
    "        return(str(codecom1).replace('B','0'))  \n",
    "    elif int(codecom1)//10000==0:\n",
    "        return('0'+str(codecom1))\n",
    "    else :\n",
    "        return(str(codecom1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "medecin_gen['code_commune2'] = medecin_gen['codecommunecoordstructure'].apply(codecom2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged_gdf = medecin_gen.merge(gdf, how='inner', left_on='code_commune2', right_on='codgeo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5265, 115)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged_gdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4538"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_merged_gdf['RPPS'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 5  : We try different merges between medecin_gen and dataF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6873, 126)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFF=medecin_gen.merge(dataF,left_on=['RPPS'],right_on=['identifiantpp'],how='inner' )\n",
    "dataFF.drop(columns=['Unnamed: 0'],inplace=True)\n",
    "dataFF.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4379"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataFF['RPPS'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFF_inner = df_merged_gdf.merge(dataF, how='inner', right_on=['identifiantpp','code_geo'],left_on=['RPPS','code_commune2'], indicator=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5294, 136)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataFF_inner.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4379"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataFF_inner['RPPS'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\agath\\AppData\\Local\\Temp\\ipykernel_19624\\3498295224.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataFF_inner['Nb_doct_2km'].replace('.',',',inplace=True)\n",
      "C:\\Users\\agath\\AppData\\Local\\Temp\\ipykernel_19624\\3498295224.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataFF_inner['Nb_doct_8km'].replace('.',',',inplace=True)\n",
      "C:\\Users\\agath\\AppData\\Local\\Temp\\ipykernel_19624\\3498295224.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataFF_inner['Nb_doct_30km'].replace('.',',',inplace=True)\n",
      "C:\\Users\\agath\\AppData\\Local\\Temp\\ipykernel_19624\\3498295224.py:4: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataFF_inner['Nb_doct_f_2km'].replace('.',',',inplace=True)\n",
      "C:\\Users\\agath\\AppData\\Local\\Temp\\ipykernel_19624\\3498295224.py:5: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataFF_inner['Nb_doct_f_8km'].replace('.',',',inplace=True)\n",
      "C:\\Users\\agath\\AppData\\Local\\Temp\\ipykernel_19624\\3498295224.py:6: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataFF_inner['Nb_doct_f_30km'].replace('.',',',inplace=True)\n",
      "C:\\Users\\agath\\AppData\\Local\\Temp\\ipykernel_19624\\3498295224.py:7: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataFF_inner['Nb_doct_D_2km'].replace('.',',',inplace=True)\n",
      "C:\\Users\\agath\\AppData\\Local\\Temp\\ipykernel_19624\\3498295224.py:8: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataFF_inner['Nb_doct_D_8km'].replace('.',',',inplace=True)\n",
      "C:\\Users\\agath\\AppData\\Local\\Temp\\ipykernel_19624\\3498295224.py:9: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataFF_inner['Nb_doct_D_30km'].replace('.',',',inplace=True)\n",
      "C:\\Users\\agath\\AppData\\Local\\Temp\\ipykernel_19624\\3498295224.py:10: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataFF_inner['Nb_doct_f_D_2km'].replace('.',',',inplace=True)\n",
      "C:\\Users\\agath\\AppData\\Local\\Temp\\ipykernel_19624\\3498295224.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataFF_inner['Nb_doct_f_D_8km'].replace('.',',',inplace=True)\n",
      "C:\\Users\\agath\\AppData\\Local\\Temp\\ipykernel_19624\\3498295224.py:12: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  dataFF_inner['Nb_doct_f_D_30km'].replace('.',',',inplace=True)\n"
     ]
    }
   ],
   "source": [
    "dataFF_inner['Nb_doct_2km'].replace('.',',',inplace=True) \n",
    "dataFF_inner['Nb_doct_8km'].replace('.',',',inplace=True) \n",
    "dataFF_inner['Nb_doct_30km'].replace('.',',',inplace=True) \n",
    "dataFF_inner['Nb_doct_f_2km'].replace('.',',',inplace=True) \n",
    "dataFF_inner['Nb_doct_f_8km'].replace('.',',',inplace=True) \n",
    "dataFF_inner['Nb_doct_f_30km'].replace('.',',',inplace=True) \n",
    "dataFF_inner['Nb_doct_D_2km'].replace('.',',',inplace=True) \n",
    "dataFF_inner['Nb_doct_D_8km'].replace('.',',',inplace=True) \n",
    "dataFF_inner['Nb_doct_D_30km'].replace('.',',',inplace=True) \n",
    "dataFF_inner['Nb_doct_f_D_2km'].replace('.',',',inplace=True) \n",
    "dataFF_inner['Nb_doct_f_D_8km'].replace('.',',',inplace=True) \n",
    "dataFF_inner['Nb_doct_f_D_30km'].replace('.',',',inplace=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFF_inner['Nb_doct_2km']=dataFF_inner['Nb_doct_2km'].astype(float) \n",
    "dataFF_inner['Nb_doct_8km']=dataFF_inner['Nb_doct_8km'].astype(float) \n",
    "dataFF_inner['Nb_doct_30km']=dataFF_inner['Nb_doct_30km'].astype(float) \n",
    "dataFF_inner['Nb_doct_f_2km']=dataFF_inner['Nb_doct_f_2km'].astype(float) \n",
    "dataFF_inner['Nb_doct_f_8km']=dataFF_inner['Nb_doct_f_8km'].astype(float) \n",
    "dataFF_inner['Nb_doct_f_30km']=dataFF_inner['Nb_doct_f_30km'].astype(float) \n",
    "dataFF_inner['Nb_doct_D_2km']=dataFF_inner['Nb_doct_D_2km'].astype(float) \n",
    "dataFF_inner['Nb_doct_D_8km']=dataFF_inner['Nb_doct_D_8km'].astype(float) \n",
    "dataFF_inner['Nb_doct_D_30km']=dataFF_inner['Nb_doct_D_30km'].astype(float) \n",
    "dataFF_inner['Nb_doct_f_D_2km']=dataFF_inner['Nb_doct_f_D_2km'].astype(float) \n",
    "dataFF_inner['Nb_doct_f_D_8km']=dataFF_inner['Nb_doct_f_D_2km'].astype(float) \n",
    "dataFF_inner['Nb_doct_f_D_30km']=dataFF_inner['Nb_doct_f_D_2km'].astype(float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFF_inner['same_gender_2km'] = dataFF_inner.apply(lambda x: x['Nb_doct_f_2km'] if x['gender']==1 else x['Nb_doct_2km']-x['Nb_doct_f_2km'], axis=1)\n",
    "dataFF_inner['same_gender_8km'] = dataFF_inner.apply(lambda x: x['Nb_doct_f_8km'] if x['gender']==1 else x['Nb_doct_8km']-x['Nb_doct_f_8km'], axis=1)\n",
    "dataFF_inner['same_gender_30km'] = dataFF_inner.apply(lambda x: x['Nb_doct_f_30km'] if x['gender']==1 else x['Nb_doct_30km']-x['Nb_doct_f_30km'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6: We save this data frame in a .csv file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFF_inner.to_csv('dataFF.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
